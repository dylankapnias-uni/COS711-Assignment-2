{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde76c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d844c50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3.10 -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c5faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('content/Almond.csv')\n",
    "\n",
    "# imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# numeric_columns = data.drop(columns=['Type']).columns\n",
    "# data[numeric_columns] = imputer.fit_transform(data[numeric_columns])\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# data['Type'] = label_encoder.fit_transform(data['Type'])\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# data[numeric_columns] = scaler.fit_transform(data[numeric_columns])\n",
    "\n",
    "# X = data.drop(columns=['Type'])\n",
    "# y = data['Type']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# X_train.head(), y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945b1c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('content/Almond.csv')\n",
    "data = data.drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "numeric_columns = data.drop(columns=['Type']).columns\n",
    "base_features = ['Length (major axis)', 'Width (minor axis)', 'Thickness (depth)']\n",
    "derived_features = ['Roundness', 'Aspect Ratio', 'Eccentricity']\n",
    "\n",
    "data[base_features] = imputer.fit_transform(data[base_features])\n",
    "\n",
    "data['Roundness'] = (4 * data['Area']) / (math.pi * (data['Length (major axis)'] ** 2))\n",
    "data['Aspect Ratio'] = (data['Length (major axis)']) / (data['Width (minor axis)'])\n",
    "data['Eccentricity'] = np.sqrt(np.clip(1 - (data['Width (minor axis)'] / data['Length (major axis)']) ** 2, 0, None))\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "data['Type'] = label_encoder.fit_transform(data['Type'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data[numeric_columns] = scaler.fit_transform(data[numeric_columns])\n",
    "\n",
    "X = data.drop(columns=['Type'])\n",
    "y = data['Type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.head(), y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ab6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0bcb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid_search_model(learning_rate, neurons):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Input(shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(neurons, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcda88a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(model=create_grid_search_model, learning_rate=0.001, neurons=32, verbose=0)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'neurons': [16, 32, 64]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Score: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "\n",
    "best_model = grid_result.best_estimator_\n",
    "best_test_acc = best_model.score(X_test, y_test)\n",
    "print(f'Test accuracy with best hyperparameters: {best_test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f41aea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = grid_result.cv_results_['mean_test_score'].reshape(len(param_grid['learning_rate']), len(param_grid['neurons']))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(scores, annot=True, xticklabels=param_grid['neurons'], yticklabels=param_grid['learning_rate'])\n",
    "plt.title('Hyperparameter Optimization: Learning Rate vs Neurons')\n",
    "plt.xlabel('Neurons')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac156407",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scores = grid_result.cv_results_['std_test_score'].reshape(len(param_grid['learning_rate']), len(param_grid['neurons']))\n",
    "mean_scores = grid_result.cv_results_['mean_test_score'].reshape(len(param_grid['learning_rate']), len(param_grid['neurons']))\n",
    "\n",
    "for i, lr in enumerate(param_grid['learning_rate']):\n",
    "    for j, neuron in enumerate(param_grid['neurons']):\n",
    "        print(f\"Learning Rate: {lr}, Neurons: {neuron}, Mean Accuracy: {mean_scores[i][j]:.3f}, Std Dev: {std_scores[i][j]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57547b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_with_optimizer(optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bc0f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rprop_optimizer = RMSprop()\n",
    "adam_optimizer = Adam()\n",
    "\n",
    "rprop_model = create_model_with_optimizer(rprop_optimizer)\n",
    "rprop_history = rprop_model.fit(X_train, y_train, \n",
    "                                epochs=20, \n",
    "                                batch_size=32, \n",
    "                                validation_data=(X_test, y_test), \n",
    "                                verbose=0)\n",
    "\n",
    "adam_model = create_model_with_optimizer(adam_optimizer)\n",
    "adam_history = adam_model.fit(X_train, y_train, \n",
    "                              epochs=20, \n",
    "                              batch_size=32, \n",
    "                              validation_data=(X_test, y_test), \n",
    "                              verbose=0)\n",
    "\n",
    "rprop_loss, rprop_acc = rprop_model.evaluate(X_test, y_test, verbose=0)\n",
    "adam_loss, adam_acc = adam_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f'RProp Test Accuracy: {rprop_acc}')\n",
    "print(f'RProp Test Loss: {rprop_loss}')\n",
    "print(f'Adam Test Accuracy: {adam_acc}')\n",
    "print(f'Adam Test Loss: {adam_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7948701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_model_train(model, X_train, y_train, epochs=20, batch_size=32):\n",
    "    rprop_optimizer = RMSprop()\n",
    "    adam_optimizer = Adam()\n",
    "    \n",
    "    adam_model = create_model_with_optimizer(adam_optimizer)\n",
    "    rprop_model = create_model_with_optimizer(rprop_optimizer)\n",
    "    \n",
    "    hybrid_train_losses = []\n",
    "    hybrid_val_losses = []\n",
    "    hybrid_train_acc = []\n",
    "    hybrid_val_acc = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        adam_updates = []\n",
    "        rprop_updates = []\n",
    "        \n",
    "        for batch in range(0, len(X_train), batch_size):\n",
    "            print(f\"Batch {batch}\")\n",
    "            X_batch = X_train[batch:batch+batch_size]\n",
    "            y_batch = y_train[batch:batch+batch_size]\n",
    "            \n",
    "            adam_model.train_on_batch(X_batch, y_batch)\n",
    "            adam_updates.append(adam_model.get_weights())\n",
    "            \n",
    "            rprop_model.train_on_batch(X_batch, y_batch)\n",
    "            rprop_updates.append(rprop_model.get_weights())\n",
    "\n",
    "        print('Getting avg.')\n",
    "        avg_updates = []\n",
    "        for adam_w, rprop_w in zip(adam_updates[-1], rprop_updates[-1]):\n",
    "            avg_w = np.mean([adam_w, rprop_w], axis=0)\n",
    "            avg_updates.append(avg_w)\n",
    "        \n",
    "        print(\"Applying avg\")\n",
    "        model.set_weights(avg_updates)\n",
    "        \n",
    "        print(\"Calculating Acc and Loss\")\n",
    "        train_loss, train_acc = hybrid_model.evaluate(X_train, y_train, verbose=0)\n",
    "        val_loss, val_acc = hybrid_model.evaluate(X_test, y_test, verbose=0)\n",
    "        hybrid_train_acc.append(train_acc)\n",
    "        hybrid_val_acc.append(val_acc)\n",
    "        hybrid_train_losses.append(train_loss)\n",
    "        hybrid_val_losses.append(val_loss)\n",
    "        \n",
    "    return hybrid_train_losses, hybrid_val_losses, hybrid_train_acc, hybrid_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f7d746",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model = create_model_with_optimizer(Adam())\n",
    "\n",
    "hybrid_train_losses, hybrid_val_losses, hybrid_train_acc, hybrid_val_acc = hybrid_model_train(hybrid_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0e2558",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb4eb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bd41a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(adam_history.history['loss'], label=f'Training Loss (Adam)')\n",
    "plt.plot(adam_history.history['val_loss'], label=f'Validation Loss (Adam)')\n",
    "\n",
    "plt.plot(rprop_history.history['loss'], label=f'Training Loss (RProp)')\n",
    "plt.plot(rprop_history.history['val_loss'], label=f'Validation Loss (RProp)')\n",
    "\n",
    "plt.plot(hybrid_train_losses, label=f'Training Loss (Hybrid)')\n",
    "plt.plot(hybrid_val_losses, label=f'Validation Loss (Hybrid)')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Run 3: Training and Validation Loss Comparison')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd5d895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
